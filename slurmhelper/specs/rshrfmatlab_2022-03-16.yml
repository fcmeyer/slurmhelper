---
spec_name: 'rshrfmatlab'
spec_version: '2022-03-16'

# -------------------------------------------------
# - Submission scripts                            -
# -------------------------------------------------

# All run script templates will be pre-formatted with these parameters.
script_global_settings: {
                          n_thr: 8,
                          mem_mb: 15000,
                          fd_thr: 0.3,
                          path_matlab: '/software/matlab-2020b-el7-x86_64/bin/matlab',
                          path_spm: '/home/fcmeyer/scratch-midway2/spm12'
}

# Header of script to be submitted to sbatch
# Very important! this is actually substiting based on what you gave us in the inputs...
# because sometimes you need to have memory on sbatch be higher than on your job!
header: |
    #!/bin/bash -e

    #SBATCH --job-name=${job_name}
    #SBATCH --output=${log_path}
    #SBATCH --partition=broadwl
    #SBATCH --nodes=1
    #SBATCH --ntasks-per-node=${n_tasks}
    #SBATCH --mem=${mem}
    #SBATCH --time=${time}
    ${job_array}

# Preamble, might include necessary modules to be loaded
preamble: |
    
    # load necessary modules
    module load python
    module load matlab/2020b
    module load fsl/6.0.4
    module load afni/21.0

    conda activate /home/fcmeyer/.conda/envs/rshrfmatlab_2022

    echo "~~~~~~~~~~~~~ BEGIN SLURM JOB ~~~~~~~~~~~~~~"

# Additional stuff to add to the end of an array
array_footer: |
    # sanity checks
    echo "SLURM_JOBID: " $SLURM_JOBID
    echo "SLURM_ARRAY_TASK_ID: " $SLURM_ARRAY_TASK_ID
    echo "SLURM_ARRAY_JOB_ID: " $SLURM_ARRAY_JOB_ID

    bash ${path_to_array}

    exit

run_script: |
    #!/bin/bash -e
    
    # get start time for timing runtime
    start=`date +%s`

    echo "Begin running job ${job_id}, corresponding to:"
    echo "Subject ${subject}, Session ${session}, Task ${task}, Run ${run}"
    echo "-----------------------------"

    rshrfmatlab --nthreads ${n_thr} --mem_mb ${mem_mb} --trim_amt ${trim_amt} --trim_tgt ${trim_tgt} \
        --participant_label ${subject} --session_label ${session} \
        --task-id ${task} --run-id ${run} --fd_thr ${fd_thr} --tr ${tr} --serial-corr "AR(1)" \
        --basis_functions sfir gamma2 gamma3 \
        --keep_deconv roi \
        --atlas-parametermaps aal3v1 craddock400 shen268 \
        --atlas-deconv aal3v1 craddock400 shen268 \
        --keep_non_olrm --keep_mat_file \
        ${path_matlab} \
        ${path_spm} \
        ${this_job_inputs_dir}/derivatives \
        ${output_base_dir} \
        ${this_job_work_dir}

    exit_status=$?

    echo "exit status: $exit_status"

    if [ $exit_status -eq 0 ]
    then
        echo "it appears things went well, go ahead and rm work and input dirs from scratch"
        rm -rf ${this_job_work_dir}
        rm -rf ${this_job_inputs_dir}
        end=`date +%s`
        runtime=$((end-start))
        echo "runtime: $runtime"
        echo "SUCCESS"
        echo $exit_status
        exit 0
    else
        echo "it appears things did not go well. we wont touch nothing"
        echo "FAILURE"
        echo $exit_status
        exit 1
    fi

clean_script: |
    #!/bin/bash -e
    
    echo "Cleaning up for job ${job_id}, corresponding to:"
    echo "Subject ${subject}, Session ${session}, Task ${task}, Run ${run}"
    echo "-----------------------------"
    
    if [ -d ${this_job_inputs_dir} ]; then
        echo "Deleting derivatives inputs for job ${job_id}..."
        rm -rf ${this_job_inputs_dir}
    else
        echo "No derivatives inputs detected for job ${job_id}. Skipping..."
    fi
    
    if [ -d ${this_job_work_dir} ]; then
        echo "Deleting working directory for job ${job_id}..."
        rm -rf ${this_job_work_dir}
    else
        echo "No working directory detected for job ${job_id}. Skipping..."
    fi
    
    if compgen -G "${this_job_output_expr_fullpath}" > /dev/null; then
        echo "Deleting partial outputs for job ${job_id}..."
        rm ${this_job_output_expr_fullpath}
    else
        echo "No partial outputs detected for job ${job_id}. Skipping..."
    fi
    
    if [ -f ${this_job_log_file} ]; then
        echo "Deleting log file for job ${job_id}..."
        rm ${this_job_log_file}
    else
        echo "No log file detected for job ${job_id}. Skipping..."
    fi
    
    echo "Done."
    
    exit

copy_script: |
    #!/bin/bash -e
    
    echo "Copying inputs for job ${job_id}, corresponding to:"
    echo "Subject ${subject}, Session ${session}, Task ${task}, Run ${run}"
    echo "-----------------------------"
    
    echo "Creating directory structure"
    
    if [ ! -d ${this_job_inputs_dir}/derivatives/fmriprep/sub-${subject}/ses-${session} ]; then
        mkdir -p ${this_job_inputs_dir}/derivatives/fmriprep/sub-${subject}
    fi
    
    if [ ! -d ${this_job_inputs_dir}/derivatives/uchicagoABCDProcessing/sub-${subject}/ses-${session} ]; then
        mkdir -p ${this_job_inputs_dir}/derivatives/uchicagoABCDProcessing/sub-${subject}
    fi
    
    echo "Copying fmriprep inputs..."
    rsync -zarv --include="*/" --include="*task-${task}_run-${run_id}_desc-confounds*" --include="*task-${task}_run-${run_id}_space-MNI152NLin6Asym_desc-brain_mask*" --exclude="*" /cds2/abcd/cold/derivatives/fmriprep/sub-${subject}/ses-${session} ${this_job_inputs_dir}/derivatives/fmriprep/sub-${subject}
    
    echo "Copying uchicagoABCDProcessing inputs..."
    rsync -zarv --include="*/" --include="*task-${task}_run-${run_id}*" --exclude="*" /cds2/abcd/cold/derivatives/uchicagoABCDProcessing/sub-${subject}/ses-${session} ${this_job_inputs_dir}/derivatives/uchicagoABCDProcessing/sub-${subject}
    
    echo "Done"
    echo "-----------------------------"
    exit

# -------------------------------------------------
# - Inputs and outputs                            -
# -------------------------------------------------

# This contains information about the jobs to be run.
# See example for details.
# database: 'rshrf_db.csv'

# Base directory where outputs are stored
output_path: "/project2/abcd/derivatives"
# Subject-specific sub-directory (e.g., for BIDS)
output_path_subject: ['restingstatehrf','sub-{subject}', 'ses-{session}', 'func']
# Subject-specific file glob (e.g., for checking outputs)
output_path_subject_expr: 'sub-{subject}_ses-{session}_task-{task}_run-{run:d}_*'

base_directory_name: 'rshrf2022'

# -------------------------------------------------
# - Job specification                             -
# -------------------------------------------------
expected_n_files: 150 # for a given run
job_ramp_up_time: {
                    minutes: 4
}
job_time: {
            minutes: 27
}
max_job_time: {
                hours: 22,
                minutes: 56
}

# -------------------------------------------------
# - Custom computation of script parameters       -
# -------------------------------------------------

# not yet working... UGHHHH
compute_custom_vars: >
    def compute_custom_vars(job_dict, dirs):
        # job_dict['run_id'] = '{run:02d}'.format(run = int(job_dict['run']))
        return job_dict